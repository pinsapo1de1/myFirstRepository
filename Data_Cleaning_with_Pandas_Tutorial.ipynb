{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "EcM7skvIdZy8"
      },
      "cell_type": "markdown",
      "source": [
        "![sslogo](https://github.com/stratascratch/stratascratch.github.io/raw/master/assets/sslogo.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "UNe-4gGI-Qvx"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning with Pandas Tutorial"
      ]
    },
    {
      "metadata": {
        "id": "DXfs53esZMbM"
      },
      "cell_type": "markdown",
      "source": [
        "To edit this notebook:\n",
        "- Save the notebook by selecting `Download .ipynb` from the `File` tab\n",
        "- Go to [Colaboratory](https://colab.research.google.com/) and upload the notebook from the `File` tab\n",
        "- Alternatively, you can import the notebook to your Google Drive and select `Open with` when you right-click. Select `Colaboratory` or `+ Connect more apps` to install Colaboratory first"
      ]
    },
    {
      "metadata": {
        "id": "KAUwvBmpDcHY"
      },
      "cell_type": "markdown",
      "source": [
        "## Install the Database Module\n",
        "\n",
        "The code below installs a postgres database module to allow our notebook to connect to the Strata Scratch database\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "SKM7C2lK-fi4"
      },
      "cell_type": "code",
      "source": [
        "!pip install psycopg2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nTtFkSnYDum4"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Required Modules\n",
        "\n",
        "Import a few required modules that enables us to query data and perform analytics"
      ]
    },
    {
      "metadata": {
        "id": "COEtgHk6kzu8"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import psycopg2 as ps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VhQxH5ilENeK"
      },
      "cell_type": "markdown",
      "source": [
        "## Connect to Strata Scratch\n",
        "\n",
        "Make sure to enter your username and database password. Your database password is not the same as your login password. You can find your database password in the Profile tab once logged into Strata Scratch."
      ]
    },
    {
      "metadata": {
        "id": "RAq6KStKk0Lj"
      },
      "cell_type": "code",
      "source": [
        "host_name = 'db-strata.stratascratch.com'\n",
        "dbname = 'db_strata'\n",
        "port = '5432'\n",
        "user_name = '' #enter username\n",
        "pwd = '' #enter your database password found in the profile tab in Strata Scratch\n",
        "\n",
        "try:\n",
        "    conn = ps.connect(host=host_name,database=dbname,user=user_name,password=pwd,port=port)\n",
        "except ps.OperationalError as e:\n",
        "    raise e\n",
        "else:\n",
        "    print('Connected!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-KeXw0cgFWKS"
      },
      "cell_type": "markdown",
      "source": [
        "## Pull Data From Strata Scratch"
      ]
    },
    {
      "metadata": {
        "id": "--Vp64-TFmpl"
      },
      "cell_type": "markdown",
      "source": [
        "#### Enter SQL code below to pull the dataset you're interested in\n",
        "\n",
        "If you get an error, it likely means that the connection timed out. Try connecting to Strata Scratch again before executing the code below.\n",
        "\n",
        "A list of datasets is found in SQL LAB in Strata Scratch."
      ]
    },
    {
      "metadata": {
        "id": "n9gIvVNUESyf"
      },
      "cell_type": "code",
      "source": [
        "#Write SQL below to pull datasets\n",
        "cur = conn.cursor()\n",
        "cur.execute(\"\"\"\n",
        "            SELECT *  FROM datasets.nfl_combine;\n",
        "            \"\"\")\n",
        "data = cur.fetchall()\n",
        "colnames = [desc[0] for desc in cur.description]\n",
        "conn.commit()\n",
        "\n",
        "#create the pandas dataframe\n",
        "data = pd.DataFrame(data)\n",
        "data.columns = colnames\n",
        "\n",
        "#close the connection\n",
        "cur.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vGAkYc58GN1G"
      },
      "cell_type": "markdown",
      "source": [
        "## Check To See If Your Pulled The Dataset\n",
        "\n",
        "Your dataset should be in a pandas dataframe named `data`"
      ]
    },
    {
      "metadata": {
        "id": "ahZcg-eKFLzE"
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nzPuTQdPeK8H"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning Tips & Tricks Using Pandas"
      ]
    },
    {
      "metadata": {
        "id": "XiCMGLdJ-QwC"
      },
      "cell_type": "markdown",
      "source": [
        "### Fill missing values for college with 'No College'\n",
        "\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html\n",
        "\n",
        "`fillna` method when given a single value like in this example fills all missing values in the dataframe with that value.\n",
        "\n",
        "When given a dictionary to the value parameter it replaces according to that dictionary.\n",
        "\n",
        "`inplace=True` makes the dataframe change permenant in the same dataframe"
      ]
    },
    {
      "metadata": {
        "id": "iyks-_Ao-QwD"
      },
      "cell_type": "code",
      "source": [
        "data.fillna(value='No College', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrekcNH--QwG"
      },
      "cell_type": "markdown",
      "source": [
        "### Remove the players that have null values for the pick\n",
        "\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html\n",
        "\n",
        "Dropna will drop rows according to some null value criteria.\n",
        "\n",
        "That criteria is defined via the `subset` parameter.\n",
        "\n",
        "`how=\"any\"` means delete row if at least one value is null.\n",
        "\n",
        "`how=\"all\"` means delete row if all values are null.\n",
        "\n",
        "`inplace=True` makes the dataframe change permenant in the same dataframe"
      ]
    },
    {
      "metadata": {
        "id": "1PSltwv4-QwH"
      },
      "cell_type": "code",
      "source": [
        "data.dropna(how='any', subset=['pick'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tKSN-eZM-QwJ"
      },
      "cell_type": "markdown",
      "source": [
        "### Investigate the unique values in the position column\n",
        "\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.unique.html\n",
        "\n",
        "The unique method returns all unique items as a numpy array.\n",
        "\n",
        "In some special cases it also returns a Categories object."
      ]
    },
    {
      "metadata": {
        "id": "FNNlg0Go-QwJ"
      },
      "cell_type": "code",
      "source": [
        "data.position.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ZQHsEC0-QwN"
      },
      "cell_type": "markdown",
      "source": [
        "### Replace RB and QB with Running Back and Quarterback\n",
        "\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html\n",
        "\n",
        "This method will change **all values** in the dataframe using a set of rules of the form:\n",
        "- Replace to_replace[0] with value[0]\n",
        "- Replace to_replace[1] with value[1]\n",
        "- ...\n",
        "\n",
        "`inplace=True` makes the dataframe change permenant in the same dataframe"
      ]
    },
    {
      "metadata": {
        "id": "_I4wROym-QwN"
      },
      "cell_type": "code",
      "source": [
        "data.position.replace(to_replace=['RB','QB'],value=['Running Back','Quarterback'], inplace=True)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4IPRftBe-QwR"
      },
      "cell_type": "markdown",
      "source": [
        "### Create dummy values for position\n",
        "\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html"
      ]
    },
    {
      "metadata": {
        "id": "jZ5Cek3W-QwT"
      },
      "cell_type": "code",
      "source": [
        "dummy_data = pd.get_dummies(data.position, prefix='Pos')\n",
        "dummy_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4fotcJNe-QwW"
      },
      "cell_type": "markdown",
      "source": [
        "### Merge the dummy data with the original data set\n",
        "\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html\n",
        "\n",
        "Merge is pandas speak for sql join.\n",
        "\n",
        "The main parameters for merge are:\n",
        "- dataframe_left which is `data` in our case\n",
        "- dataframe_right which is `data` in our case\n",
        "- how which describes the type of SQL JOIN to perform. Some possible values are \"left\", \"right\", \"outer\", \"inner\"\n",
        "\n",
        "With that in place only thing left to decide is what to JOIN on.\n",
        "- We must choose the join keys for both dataframes.\n",
        "- One choice is to use the index as we do here (for both dataframes actually)\n",
        "- Another choice is to use columns which is controlled via the parameters left_on and right_on.\n",
        "- You must not set both left_on and left_index. Same for right.\n",
        "\n",
        "In a simplified case when you have columns with same name in both dataframes you can use only the `on` parameter."
      ]
    },
    {
      "metadata": {
        "id": "YAntGYzO-QwW"
      },
      "cell_type": "code",
      "source": [
        "data.merge(dummy_data, how='inner', left_index=True, right_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "26LduKo7-QwY"
      },
      "cell_type": "markdown",
      "source": [
        "### Convert weight from lbs to kg\n",
        "\n",
        "Remmeber: pandas columns are series but they can do all arithmetic stuff that numpy arrays can do."
      ]
    },
    {
      "metadata": {
        "id": "zMih86cs-QwZ"
      },
      "cell_type": "code",
      "source": [
        "data['weight_kg'] = data.weight/2.2\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfglFn-s-Qwb"
      },
      "cell_type": "markdown",
      "source": [
        "### Capitalize name\n",
        "\n",
        "- https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html\n",
        "\n",
        "Apply is a very versatile function which allows arbitrary data transformations.\n",
        "\n",
        "The main parameters of apply are the function and the axis.\n",
        "\n",
        "When dealing with columns as in this example, there is no axis, but when using apply on the whole dataframe we must use either axis=1 which means apply over rows or axis=0 which means apply over columns.\n",
        "\n",
        "In this example we apply `str.upper` over the values in the name column."
      ]
    },
    {
      "metadata": {
        "id": "I4W73kfN-Qwb"
      },
      "cell_type": "code",
      "source": [
        "# need the apply function if you're doing an operation on a column. Python doens't know to apply it to the entire dataset.\n",
        "\n",
        "data.name.apply(str.upper).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aLKGLQm4-Qwe"
      },
      "cell_type": "markdown",
      "source": [
        "### Lambda Functions\n",
        "\n",
        "Lambda functions are short, compact functions in python. They can have any number of arguments but only one expression. The expression is evaluated and returned. Lambda functions can be used wherever function objects are required.\n",
        "\n",
        "Example:\n",
        "```\n",
        "double = lambda x: x * 2\n",
        "\n",
        "print(double(5))\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Output would be `10`\n",
        "\n",
        "This lambda function will double any value in `x`."
      ]
    },
    {
      "metadata": {
        "id": "z-X2esIKfgit"
      },
      "cell_type": "markdown",
      "source": [
        "#### Reverse order of first and last name\n",
        "\n",
        "`lambda x:'{0}, {1}'.format(x['lastname'], x['firstname'])`\n",
        "- x is now a row (**axis=1**) which is of type Series. we can access firstname as x['firstname'] or x.firstname as in any other series.\n",
        "- The format method in python replaces {i} with i-th argument. So {0} gets replaced with first argument which is x['lastname'] and {1} will get replaced with x['firstname']\n",
        "- Thus this function takes a row as input and outputs a string which contains the last name followed by the first name\n",
        "\n",
        "We apply this function over all rows (**axis=1**) and obtain a series as a result.\n",
        "\n",
        "We store that series in our dataframe with the assignment."
      ]
    },
    {
      "metadata": {
        "id": "WahtXitG-Qwf"
      },
      "cell_type": "code",
      "source": [
        "data['last_firstname'] = data.apply(lambda x:'{0}, {1}'.format(x['lastname'], x['firstname']), axis=1)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
